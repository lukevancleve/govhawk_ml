{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload local modules if they've changed.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.read_parallel import read_parallel_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.deeplegis import legislationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 199451\n",
      "Reduced number of examples:  199\n",
      "Took 0.01049038569132487 min to open 199 files with 20 processes.\n"
     ]
    }
   ],
   "source": [
    "REDUCE_BY_FACTOR = 1000 # Make the dataset smaller for development purposes\n",
    "train_test_ratio = 0.91\n",
    "train_valid_ratio = 0.90\n",
    "\n",
    "if 'DATA_VOL' not in os.environ:\n",
    "    # Manually set:\n",
    "    DATA_VOL = '/home/luke/tmp_vol/'\n",
    "else:\n",
    "    DATA_VOL = os.environ['DATA_VOL']\n",
    "    \n",
    "# Pre-wrangled metadata\n",
    "df = pd.read_csv(\"../references/derived/ml_data.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "df.id = df.id.astype(int)    \n",
    "print(f\"Original number of examples: {len(df)}\")\n",
    "df = df.sample(n=int(len(df)/REDUCE_BY_FACTOR)) #\n",
    "print(f\"Reduced number of examples:  {len(df)}\")\n",
    "\n",
    "tmp = read_parallel_local(df['id'], DATA_VOL + \"/clean/\")\n",
    "df['text'] = tmp\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "sc_id_encoder = LabelEncoder()\n",
    "df['sc_id_cat'] = sc_id_encoder.fit_transform(df['sc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_id</th>\n",
       "      <th>version_number</th>\n",
       "      <th>id</th>\n",
       "      <th>partisan_lean</th>\n",
       "      <th>sc_id</th>\n",
       "      <th>signed</th>\n",
       "      <th>text</th>\n",
       "      <th>sc_id_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1296772</td>\n",
       "      <td>1</td>\n",
       "      <td>2533454</td>\n",
       "      <td>0.691329</td>\n",
       "      <td>641-2</td>\n",
       "      <td>0</td>\n",
       "      <td>assembly, no. state of new jersey 219th legisl...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244982</td>\n",
       "      <td>1</td>\n",
       "      <td>2434261</td>\n",
       "      <td>0.398339</td>\n",
       "      <td>622-1</td>\n",
       "      <td>0</td>\n",
       "      <td>florida senate sb by senator baxley 2020308 a ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1204463</td>\n",
       "      <td>2</td>\n",
       "      <td>2320565</td>\n",
       "      <td>0.538639</td>\n",
       "      <td>587-2</td>\n",
       "      <td>0</td>\n",
       "      <td>i 116th congress 1st session  to require a re...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1274032</td>\n",
       "      <td>1</td>\n",
       "      <td>2490834</td>\n",
       "      <td>0.691329</td>\n",
       "      <td>641-2</td>\n",
       "      <td>0</td>\n",
       "      <td>assembly, no. state of new jersey 219th legisl...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1151119</td>\n",
       "      <td>1</td>\n",
       "      <td>2199556</td>\n",
       "      <td>0.416977</td>\n",
       "      <td>609-1</td>\n",
       "      <td>0</td>\n",
       "      <td>enter search terms    introduced version | se...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_id  version_number       id  partisan_lean  sc_id  signed  \\\n",
       "0  1296772               1  2533454       0.691329  641-2       0   \n",
       "1  1244982               1  2434261       0.398339  622-1       0   \n",
       "2  1204463               2  2320565       0.538639  587-2       0   \n",
       "3  1274032               1  2490834       0.691329  641-2       0   \n",
       "4  1151119               1  2199556       0.416977  609-1       0   \n",
       "\n",
       "                                                text  sc_id_cat  \n",
       "0  assembly, no. state of new jersey 219th legisl...         68  \n",
       "1  florida senate sb by senator baxley 2020308 a ...         52  \n",
       "2   i 116th congress 1st session  to require a re...         25  \n",
       "3  assembly, no. state of new jersey 219th legisl...         68  \n",
       "4   enter search terms    introduced version | se...         44  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_length': 128, 'train_batch_size': 32, 'testing': False, 'train_test_ratio': 0.91, 'train_valid_ratio': 0.9}\n",
      "Training size: (162, 7)\n",
      "Validation size: (19, 7)\n",
      "Test size: (18, 7)\n",
      "({'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[    0,    30,    35, ..., 47252,   740,     2],\n",
      "       [    0,  9251,     9, ...,     6,    11,     2],\n",
      "       [    0, 24079,    18, ..., 44347, 28791,     2],\n",
      "       ...,\n",
      "       [    0, 44979,     6, ...,    13,  1680,     2],\n",
      "       [    0,  3138,  1087, ...,    10,  4874,     2],\n",
      "       [    0,   200,  1675, ...,  2052,     7,     2]], dtype=int32)>, 'partisan_lean': <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.39683497, 0.20165333, 0.42942113, 0.6913286 , 0.32524636,\n",
      "       0.36973906, 0.41637418, 0.2714404 , 0.29621407, 0.38731214,\n",
      "       0.7381234 , 0.32524636, 0.38731214, 0.3826962 , 0.59868157,\n",
      "       0.65328044, 0.32524636, 0.6       , 0.5386392 , 0.39683497,\n",
      "       0.7381234 , 0.62637186, 0.5386392 , 0.6289722 , 0.62637186,\n",
      "       0.117846  , 0.29411766, 0.43693665, 0.5       , 0.6913286 ,\n",
      "       0.43693665, 0.29447854], dtype=float32)>}, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 32\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90\n",
    "print(config)\n",
    "legis_builder = legislationDataset(config)\n",
    "train_stream, val_stream, test_stream = legis_builder.create_batch_stream(df)\n",
    "for elem in train_stream.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (162, 7)\n",
      "Validation size: (19, 7)\n",
      "Test size: (18, 7)\n",
      "({'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[    0, 13011,  1594, ...,  4361,     8,     2],\n",
      "       [    0, 29886,  2546, ...,    13,     8,     2],\n",
      "       [    0,   134, 42957, ...,     6,    37,     2],\n",
      "       ...,\n",
      "       [    0,  2810,    10, ..., 14542,    16,     2],\n",
      "       [    0,    11,     5, ...,  1683,    23,     2],\n",
      "       [    0,    92,  1423, ..., 10435,  1623,     2]], dtype=int32)>}, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "from src.models.deeplegis import legislationDatasetText\n",
    "legis_builder = legislationDatasetText(config)\n",
    "train_stream, val_stream, test_stream = legis_builder.create_batch_stream(df)\n",
    "for elem in train_stream.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(sc_id_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_length': 128, 'train_batch_size': 32, 'testing': False, 'train_test_ratio': 0.91, 'train_valid_ratio': 0.9, 'n_sc_id_classes': 70}\n",
      "Training size: (162, 8)\n",
      "Validation size: (19, 8)\n",
      "Test size: (18, 8)\n",
      "({'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[    0, 28696, 24916, ...,    42,  2810,     2],\n",
      "       [    0,  2362,   455, ...,     1,     1,     1],\n",
      "       [    0, 44979,     6, ...,  3072, 33799,     2],\n",
      "       ...,\n",
      "       [    0,  1368,   438, ...,   401, 33279,     2],\n",
      "       [    0, 45927,  1270, ...,    76, 25029,     2],\n",
      "       [    0,  2942,  1732, ...,  2945,  1218,     2]], dtype=int32)>, 'partisan_lean': <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.24377888, 0.7381234 , 0.63756734, 0.7085218 , 0.525     ,\n",
      "       0.6913286 , 0.6913286 , 0.42966998, 0.62551236, 0.7085218 ,\n",
      "       0.8953301 , 0.62637186, 0.24377888, 0.7381234 , 0.32524636,\n",
      "       0.51692516, 0.2651231 , 0.7542074 , 0.65328044, 0.21333334,\n",
      "       0.68410516, 0.42966998, 0.51692516, 0.7085218 , 0.5386392 ,\n",
      "       0.4247663 , 0.4258017 , 0.2651231 , 0.23076923, 0.36921602,\n",
      "       0.48706314, 0.28467268], dtype=float32)>, 'version_number': <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([1., 2., 1., 2., 2., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1.,\n",
      "       3., 2., 2., 1., 1., 2., 2., 2., 1., 1., 1., 4., 4., 1., 1.],\n",
      "      dtype=float32)>, 'sc_ids': <tf.Tensor: shape=(32, 1, 70), dtype=int32, numpy=\n",
      "array([[[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 1, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>}, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 32\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90\n",
    "config['n_sc_id_classes'] = len(sc_id_encoder.classes_)\n",
    "print(config)\n",
    "from src.models.deeplegis import legislationDatasetAll\n",
    "legis_builder = legislationDatasetAll(config)\n",
    "train_stream, val_stream, test_stream = legis_builder.create_batch_stream(df)\n",
    "for elem in train_stream.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 32\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90\n",
    "config['n_sc_id_classes'] = len(sc_id_encoder.classes_)\n",
    "print(config)\n",
    "from src.models.deeplegis import legislationDatasetRevCat\n",
    "legis_builder = legislationDatasetRevCat(config)\n",
    "train_stream, val_stream, test_stream = legis_builder.create_batch_stream(df)\n",
    "for elem in train_stream.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (32669, 7)\n",
      "Validation size: (3630, 7)\n",
      "Test size: (3591, 7)\n"
     ]
    }
   ],
   "source": [
    "df_train_full, df_test = train_test_split(df, train_size = train_test_ratio, random_state = 1, stratify = df.signed.values)\n",
    "df_train, df_valid = train_test_split(df_train_full, train_size = train_valid_ratio, random_state = 1, stratify = df_train_full.signed.values)\n",
    "print(f\"Training size: {df_train.shape}\")\n",
    "print(f\"Validation size: {df_valid.shape}\")\n",
    "print(f\"Test size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0,1]\n",
    "max_length = 128\n",
    "def to_feature2(text, label, partisan_lean, label_list=label_list, max_length=max_length, tokenizer=lf_tokenizer):\n",
    "  \n",
    "    output = tokenizer(text.numpy().decode('ascii'), return_tensors=\"tf\", truncation=True, padding='max_length', max_length=max_length)\n",
    "    \n",
    "    return (tf.squeeze(output['input_ids'],0), tf.cast(label, 'int32'), tf.cast(partisan_lean, 'float32'))\n",
    "\n",
    "def to_feature_map2(text, label, partisan_lean):\n",
    "    input_ids, label_id, partisan_lean  \\\n",
    "       = tf.py_function(to_feature2, [text, label, partisan_lean], Tout = [tf.int32, tf.int32, tf.float32])\n",
    "    \n",
    "    input_ids.set_shape([max_length])\n",
    "    label_id.set_shape([])\n",
    "    partisan_lean.set_shape([])\n",
    "    \n",
    "    x = {\n",
    "        'input_ids': input_ids,\n",
    "        'partisan_lean': partisan_lean\n",
    "    }\n",
    "    \n",
    "    return (x, label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "#with tf.device('/cpu:0'):\n",
    "train_data = (train_data1.map(to_feature_map2, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "             \n",
    "             .shuffle(1000)\n",
    "             .batch(train_batch_size, drop_remainder=True)\n",
    "             .prefetch(tf.data.experimental.AUTOTUNE) \n",
    "             )\n",
    "\n",
    "val_data = (val_data1.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "             .batch(train_batch_size, drop_remainder=True)\n",
    "             .prefetch(tf.data.experimental.AUTOTUNE) \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[    0, 19707,  5375, ...,     9,    10,     2],\n",
      "       [    0, 37959,   288, ...,    74, 26845,     2],\n",
      "       [    0,    92,  1423, ...,  9657,   194,     2],\n",
      "       ...,\n",
      "       [    0,  2362,   455, ...,     1,     1,     1],\n",
      "       [    0,   200,  1675, ...,   910,  9426,     2],\n",
      "       [    0, 24837,  1852, ...,  2342,   368,     2]], dtype=int32)>, 'partisan_lean': <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.3443472 , 0.6289722 , 0.7085218 , 0.2651231 , 0.595405  ,\n",
      "       0.48706314, 0.36427715, 0.479158  , 0.6       , 0.58278143,\n",
      "       0.40122998, 0.42693365, 0.479158  , 0.42966998, 0.23762377,\n",
      "       0.7381234 , 0.42693365, 0.7085218 , 0.23611817, 0.23611817,\n",
      "       0.5386392 , 0.29411766, 0.23762377, 0.42942113, 0.48706314,\n",
      "       0.7085218 , 0.23076923, 0.23611817, 0.3826962 , 0.7085218 ,\n",
      "       0.29447854, 0.55      ], dtype=float32)>}, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "#train_data.take(1)\n",
    "for elem in train_data.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFLongformerModel, TFLongformerForSequenceClassification\n",
    "from transformers import LongformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFLongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFLongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'partisan_lean'])\n"
     ]
    }
   ],
   "source": [
    "# Docs for tokenizer call:\n",
    "# https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer\n",
    "temp = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\", padding='max_length', max_length=max_length)\n",
    "inputs ={}\n",
    "inputs['input_ids'] = temp['input_ids']\n",
    "#inputs[\"labels\"] = tf.reshape(tf.constant(1), (-1, 1)) # Batch size 1\n",
    "inputs[\"partisan_lean\"] =tf.expand_dims(tf.convert_to_tensor(0.60, dtype='float32', name='partisan_lean'), axis=0)\n",
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6], dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['partisan_lean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "longformer (TFLongformerMainLay multiple             148068864   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_11 (Sl (None, 768)          0           longformer[16][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_709 (Dropout)           (None, 768)          0           tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "partisan_lean (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_10 (TFOpLambda)       (None, 769)          0           dropout_709[0][0]                \n",
      "                                                                 partisan_lean[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 700)          539000      tf.concat_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_710 (Dropout)           (None, 700)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            701         dropout_710[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 148,608,565\n",
      "Trainable params: 148,608,565\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ids = tf.keras.Input((max_length), dtype=tf.int32, name='input_ids')\n",
    "pl = tf.keras.Input((1, ), dtype=tf.float32, name='partisan_lean')\n",
    "x = model.longformer(ids)\n",
    "x = x['last_hidden_state'][:,0,:]\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.concat([x, pl], axis=-1)\n",
    "x = tf.keras.layers.Dense(700, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "dl_model = tf.keras.Model(inputs={\"input_ids\":ids,\"partisan_lean\":pl}, outputs=[x])\n",
    "\n",
    "print(dl_model.summary())\n",
    "a  = dl_model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "          loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics = [tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dl_model.fit(train_data,\n",
    "                      validation_data=val_data,\n",
    "                      epochs=1,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 768])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.models.deeplegis import *    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing DeepLegis: ['lm_head']\n",
      "- This IS expected if you are initializing DeepLegis from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DeepLegis from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of DeepLegis were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing DeepLegis: ['lm_head']\n",
      "- This IS expected if you are initializing DeepLegis from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DeepLegis from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of DeepLegis were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'partisan_lean'])\n",
      "odict_keys(['loss', 'logits'])\n"
     ]
    }
   ],
   "source": [
    "dl = DeepLegis.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "outputs = dl(inputs)\n",
    "print(inputs.keys())\n",
    "print(outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "govhawk_kernel",
   "language": "python",
   "name": "govhawk_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random \n",
    "import spacy\n",
    "import os\n",
    "import sys\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# Load the local code\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.read_parallel import read_parallel_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.10\n",
    "train_valid_ratio = 0.80\n",
    "first_n_words = 512\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\", disable = ['ner', 'tagger', 'parser', 'textcat'])\n",
    "#nlp.max_length = 10000000\n",
    "\n",
    "#df_ml = pd.read_csv(\"temp_vn.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "#df_ml = df_ml[df_ml.len != -1]\n",
    "#df_ml = df_ml[~df_ml.id.isna()]\n",
    "#df_ml.id = df_ml.id.astype(int)\n",
    "#df_ml = df_ml.sample(n=N_SAMPLE)  # random subsample to get going quicker\n",
    "#df_ml['text'] = \"zzz\"\n",
    "#df_ml = df_ml.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 199451\n",
      "Reduced number of examples:  9972\n",
      "Took 0.8421096086502076 min to open 9972 files with 20 processes.\n"
     ]
    }
   ],
   "source": [
    "REDUCE_BY_FACTOR = 20.0 # Make the dataset smaller for development purposes\n",
    "\n",
    "if 'DATA_VOL' not in os.environ:\n",
    "    # Manually set:\n",
    "    DATA_VOL = '/home/luke/tmp_vol'\n",
    "else:\n",
    "    DATA_VOL = os.environ['DATA_VOL']\n",
    "    \n",
    "# Pre-wrangled metadata\n",
    "df = pd.read_csv(\"../references/derived/ml_data.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "df.id = df.id.astype(int)    \n",
    "print(f\"Original number of examples: {len(df)}\")\n",
    "df = df.sample(n=int(len(df)/REDUCE_BY_FACTOR)) #\n",
    "print(f\"Reduced number of examples:  {len(df)}\")\n",
    "\n",
    "df['text'] = read_parallel_local(df['id'], DATA_VOL + \"/clean/\")\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.301609\n"
     ]
    }
   ],
   "source": [
    "def trim_string(x):\n",
    "    x = x.split(maxsplit=first_n_words)\n",
    "    x = ' '.join(x[:first_n_words])\n",
    "    return x\n",
    "    \n",
    "#    tokens = nlp(d1)\n",
    "#    str_tokens = [token.orth_ for token in tokens[:512]]\n",
    "#    df_ml.at[i, 'text'] = \" \".join(str_tokens)\n",
    "#    return(1)\n",
    "    \n",
    "startTime2 = datetime.now()\n",
    "for i in range(len(df_ml)):\n",
    "    df_ml.at[i, 'text'] = trim_string(df_ml.at[i, 'text'])\n",
    "print(datetime.now()-startTime2)\n",
    "\n",
    "# 43 min to process all the datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_id</th>\n",
       "      <th>version_number</th>\n",
       "      <th>id</th>\n",
       "      <th>partisan_lean</th>\n",
       "      <th>sc_id</th>\n",
       "      <th>signed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241311</td>\n",
       "      <td>2</td>\n",
       "      <td>2425753</td>\n",
       "      <td>0.538639</td>\n",
       "      <td>587-2</td>\n",
       "      <td>0</td>\n",
       "      <td>i 116th congress 1st session to direct the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1125114</td>\n",
       "      <td>1</td>\n",
       "      <td>2161662</td>\n",
       "      <td>0.325274</td>\n",
       "      <td>600-1</td>\n",
       "      <td>0</td>\n",
       "      <td>mississippi legislature regular session to: ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1318520</td>\n",
       "      <td>1</td>\n",
       "      <td>2588301</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>610-2</td>\n",
       "      <td>0</td>\n",
       "      <td>hb 275: \"an act relating to penalties for moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304520</td>\n",
       "      <td>1</td>\n",
       "      <td>2545237</td>\n",
       "      <td>0.157102</td>\n",
       "      <td>639-2</td>\n",
       "      <td>0</td>\n",
       "      <td>20lso-0134 state of wyoming house bill no. hb0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1320840</td>\n",
       "      <td>1</td>\n",
       "      <td>2575137</td>\n",
       "      <td>0.873694</td>\n",
       "      <td>635-2</td>\n",
       "      <td>0</td>\n",
       "      <td>h 7729state of rhode island in general assembl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_id  version_number       id  partisan_lean  sc_id  signed  \\\n",
       "0  1241311               2  2425753       0.538639  587-2       0   \n",
       "1  1125114               1  2161662       0.325274  600-1       0   \n",
       "2  1318520               1  2588301       0.350000  610-2       0   \n",
       "3  1304520               1  2545237       0.157102  639-2       0   \n",
       "4  1320840               1  2575137       0.873694  635-2       0   \n",
       "\n",
       "                                                text  \n",
       "0  i 116th congress 1st session to direct the sec...  \n",
       "1  mississippi legislature regular session to: ru...  \n",
       "2  hb 275: \"an act relating to penalties for moto...  \n",
       "3  20lso-0134 state of wyoming house bill no. hb0...  \n",
       "4  h 7729state of rhode island in general assembl...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i 116th congress 1st session to direct the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>mississippi legislature regular session to: ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hb 275: \"an act relating to penalties for moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20lso-0134 state of wyoming house bill no. hb0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>h 7729state of rhode island in general assembl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signed                                               text\n",
       "0       0  i 116th congress 1st session to direct the sec...\n",
       "1       0  mississippi legislature regular session to: ru...\n",
       "2       0  hb 275: \"an act relating to penalties for moto...\n",
       "3       0  20lso-0134 state of wyoming house bill no. hb0...\n",
       "4       0  h 7729state of rhode island in general assembl..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert = df_ml[['signed', 'text']]\n",
    "df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = 'bert_classification'\n",
    "\n",
    "# Train-test split\n",
    "df_train_full, df_test = train_test_split(df_bert, train_size = train_test_ratio, random_state = 1)\n",
    "\n",
    "# Train-valid split\n",
    "df_train, df_valid = train_test_split(df_train_full, train_size = train_valid_ratio, random_state = 1)\n",
    "\n",
    "# Write preprocessed data\n",
    "df_train.to_csv(destination_folder + '/train.csv', index=False)\n",
    "df_valid.to_csv(destination_folder + '/valid.csv', index=False)\n",
    "df_test.to_csv(destination_folder + '/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and prepare\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Model parameter\n",
    "MAX_SEQ_LEN = first_n_words\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('label', label_field), ('text', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=destination_folder, train='train.csv', validation='valid.csv',\n",
    "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9b7c4a596534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.iterator.Iterator at 0x7f65fdd83160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT().encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_custom(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.bert_model = BertModel.from_pretrained(options_name)\n",
    "        self.fc1 = torch.nn.Linear(770, 770)\n",
    "        self.fc2 = torch.nn.Linear(770, 2)\n",
    "\n",
    "    def forward(self, text, partisan_lean, revision_number, label):\n",
    "        \n",
    "        h = self.bert(text)\n",
    "        h_new = torch.cat(partisan_lean, revision_number, h)\n",
    "        dense1 = torch.nn.relu(self.fc1(h_new))\n",
    "        y_pred = torch.nn.Softmax(self.fc2(dense1), dim=1)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions\n",
    "\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BucketIterator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5a6858032fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'BucketIterator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for (label, text), _ in train_iter:\n",
    "    print(label)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/4000], Train Loss: 0.4506, Valid Loss: 0.5224\n",
      "Model saved to ==> bert_classification/model.pt\n",
      "Model saved to ==> bert_classification/metrics.pt\n",
      "Epoch [1/20], Step [200/4000], Train Loss: 0.3860, Valid Loss: 0.6524\n",
      "Epoch [2/20], Step [300/4000], Train Loss: 0.4529, Valid Loss: 0.5051\n",
      "Model saved to ==> bert_classification/model.pt\n",
      "Model saved to ==> bert_classification/metrics.pt\n",
      "Epoch [2/20], Step [400/4000], Train Loss: 0.3806, Valid Loss: 0.6375\n",
      "Epoch [3/20], Step [500/4000], Train Loss: 0.4471, Valid Loss: 0.4890\n",
      "Model saved to ==> bert_classification/model.pt\n",
      "Model saved to ==> bert_classification/metrics.pt\n",
      "Epoch [3/20], Step [600/4000], Train Loss: 0.3337, Valid Loss: 0.6113\n",
      "Epoch [4/20], Step [700/4000], Train Loss: 0.4306, Valid Loss: 0.4763\n",
      "Model saved to ==> bert_classification/model.pt\n",
      "Model saved to ==> bert_classification/metrics.pt\n",
      "Epoch [4/20], Step [800/4000], Train Loss: 0.2971, Valid Loss: 0.5836\n",
      "Epoch [5/20], Step [900/4000], Train Loss: 0.3842, Valid Loss: 0.4913\n",
      "Epoch [5/20], Step [1000/4000], Train Loss: 0.2092, Valid Loss: 0.7328\n",
      "Epoch [6/20], Step [1100/4000], Train Loss: 0.3507, Valid Loss: 0.4770\n",
      "Epoch [6/20], Step [1200/4000], Train Loss: 0.1442, Valid Loss: 0.6427\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4b83b2ad6254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-4b83b2ad6254>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, valid_loader, num_epochs, eval_every, file_path, best_valid_loss)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/govhawk_ml/env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/govhawk_ml/env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = NUM_EPOCHS,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (labels, text), _ in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)           \n",
    "            labels = labels.to(device)\n",
    "            text = text.type(torch.LongTensor)  \n",
    "            text = text.to(device)\n",
    "            output = model(text, labels)\n",
    "            loss, _ = output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "\n",
    "                    # validation loop\n",
    "                    for (labels, text), _ in valid_loader:\n",
    "                        labels = labels.type(torch.LongTensor)           \n",
    "                        labels = labels.to(device)\n",
    "                        text = text.type(torch.LongTensor)  \n",
    "                        text = text.to(device)\n",
    "                        output = model(text, labels)\n",
    "                        loss, _ = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "#train(model=model, optimizer=optimizer)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== bert_classification/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== bert_classification/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000      1236\n",
      "           0     0.8623    1.0000    0.9261      7739\n",
      "\n",
      "    accuracy                         0.8623      8975\n",
      "   macro avg     0.4311    0.5000    0.4630      8975\n",
      "weighted avg     0.7435    0.8623    0.7985      8975\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/repos/govhawk_ml/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, text), _ in test_loader:\n",
    "\n",
    "                labels = labels.type(torch.LongTensor)           \n",
    "                labels = labels.to(device)\n",
    "                text = text.type(torch.LongTensor)  \n",
    "                text = text.to(device)\n",
    "                output = model(text, labels)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Signed', 'Failed'])\n",
    "    ax.yaxis.set_ticklabels(['Signed', 'Failed'])\n",
    "    \n",
    "best_model = BERT().to(device)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
    "\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432222222222222"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5966+723)/(5966+723+638+1673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 samples, 5 epochs, 128 seq_len:  accuracy = 0.743\n",
    "# 100,000 samples, 5 epochs, 128 seq_len: accuracy = 0.818\n",
    "# 10,000 samples, 5 epochs, 512 seq_len, accuracy = 0.747\n",
    "# 10,000 samples, 5 epochs, 512 seq len, accuracy = 0.687\n",
    "print(datetime.now() - startTime)\n",
    "print(\"sequence length:{}, N samples:{}, time:{}\".format(MAX_SEQ_LEN, N_SAMPLE, datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "govhawk_kernel",
   "language": "python",
   "name": "govhawk_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

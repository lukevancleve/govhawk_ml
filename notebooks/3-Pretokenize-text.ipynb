{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extensive-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.data.read_parallel import read_parallel_local\n",
    "from src.models.deeplegis import *\n",
    "from src.models.data_loader import *\n",
    "from src.models.configurationClasses import deepLegisConfig\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "import pandarallel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apparent-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = deepLegisConfig(\"bert_128.json\", project_root=\"../\")\n",
    "# df, encoder = createDeepLegisDataFrame(config, read_cached=False)\n",
    "# df.to_pickle(\"/home/luke/ml_govhawk_prod_output/preprocessed_df_128.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 199646\n",
      "Loading 199646 text files\n",
      "Took 6.862114743391673 min (411.7269082069397 sec)to open 199646 files with 20 processes.\n",
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Tokenized in 127.19514717706667 min -  7631.7088 seconds\n"
     ]
    }
   ],
   "source": [
    "# config = deepLegisConfig(\"bert_512.json\", project_root=\"../\")\n",
    "# df, encoder = createDeepLegisDataFrame(config, read_cached=False)\n",
    "# df.to_pickle(\"/home/luke/ml_govhawk_prod_output/preprocessed_df_512.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No max length. For use with longformer.\n",
    "# from transformers import LongformerTokenizer\n",
    "# tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "# def tokenizer_wrapper(text):\n",
    "#     d = tokenizer(text, truncation=Fale, padding=None, max_length=None)\n",
    "#     return d['input_ids']\n",
    "# tic = time.perf_counter()\n",
    "# df['tokens'] = df.text.parallel_apply( tokenizer_wrapper)\n",
    "# toc = time.perf_counter()\n",
    "# print(f\"Tokenized in {(toc-tic)/60.0} min -  {toc - tic:0.4f} seconds\")\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(\"/home/luke/ml_govhawk_prod_output/preprocessed_df_longformer_unlimited.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-polish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infectious-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "copyrighted-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.data.read_parallel import read_parallel_local\n",
    "from src.models.deeplegis import *\n",
    "from src.models.data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 199646\n",
      "Reduced number of examples:  199646\n",
      "Took 2.1606207966804503 min to open 199646 files with 20 processes.\n"
     ]
    }
   ],
   "source": [
    "REDUCE_BY_FACTOR = 1 # Make the dataset smaller for development purposes\n",
    "train_test_ratio = 0.91\n",
    "train_valid_ratio = 0.90\n",
    "\n",
    "if 'DATA_VOL' not in os.environ:\n",
    "    # Manually set:\n",
    "    DATA_VOL = '/home/luke/tmp_vol'\n",
    "else:\n",
    "    DATA_VOL = os.environ['DATA_VOL']\n",
    "    \n",
    "# Pre-wrangled metadata\n",
    "df = pd.read_csv(\"../references/derived/ml_data.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "df.id = df.id.astype(int)    \n",
    "print(f\"Original number of examples: {len(df)}\")\n",
    "df = df.sample(n=int(len(df)/REDUCE_BY_FACTOR)) #\n",
    "print(f\"Reduced number of examples:  {len(df)}\")\n",
    "\n",
    "tmp = read_parallel_local(df['id'], DATA_VOL + \"/clean/\")\n",
    "df['text'] = tmp\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "sc_id_encoder = LabelEncoder()\n",
    "df['sc_id_cat'] = sc_id_encoder.fit_transform(df['sc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vietnamese-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (163509, 8)\n",
      "Validation size: (18168, 8)\n",
      "Test size: (17969, 8)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "partisan_lean (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "version_number (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sc_id (InputLayer)              [(None, 134)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 136)          0           partisan_lean[0][0]              \n",
      "                                                                 version_number[0][0]             \n",
      "                                                                 sc_id[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "no_text_dense_layer (Dense)     (None, 700)          95900       tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 700)          0           no_text_dense_layer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            701         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 96,601\n",
      "Trainable params: 96,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "1277/1277 [==============================] - 128s 100ms/step - loss: 0.3110 - binary_accuracy: 0.8808 - precision: 0.6499 - recall: 0.2596 - auc: 0.8165 - val_loss: 0.2673 - val_binary_accuracy: 0.8904 - val_precision: 0.6637 - val_recall: 0.4175 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00001: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 2/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2659 - binary_accuracy: 0.8908 - precision: 0.6746 - recall: 0.3919 - auc: 0.8783 - val_loss: 0.2649 - val_binary_accuracy: 0.8906 - val_precision: 0.6688 - val_recall: 0.4111 - val_auc: 0.8811\n",
      "\n",
      "Epoch 00002: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 3/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2638 - binary_accuracy: 0.8915 - precision: 0.6754 - recall: 0.4011 - auc: 0.8803 - val_loss: 0.2646 - val_binary_accuracy: 0.8899 - val_precision: 0.6978 - val_recall: 0.3569 - val_auc: 0.8814\n",
      "\n",
      "Epoch 00003: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 4/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2626 - binary_accuracy: 0.8919 - precision: 0.6771 - recall: 0.4022 - auc: 0.8815 - val_loss: 0.2631 - val_binary_accuracy: 0.8909 - val_precision: 0.6710 - val_recall: 0.4111 - val_auc: 0.8822\n",
      "\n",
      "Epoch 00004: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 5/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2614 - binary_accuracy: 0.8925 - precision: 0.6790 - recall: 0.4086 - auc: 0.8828 - val_loss: 0.2625 - val_binary_accuracy: 0.8919 - val_precision: 0.6737 - val_recall: 0.4203 - val_auc: 0.8826\n",
      "\n",
      "Epoch 00005: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 6/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2612 - binary_accuracy: 0.8931 - precision: 0.6816 - recall: 0.4119 - auc: 0.8828 - val_loss: 0.2627 - val_binary_accuracy: 0.8916 - val_precision: 0.6764 - val_recall: 0.4111 - val_auc: 0.8827\n",
      "\n",
      "Epoch 00006: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 7/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2607 - binary_accuracy: 0.8927 - precision: 0.6794 - recall: 0.4100 - auc: 0.8831 - val_loss: 0.2621 - val_binary_accuracy: 0.8920 - val_precision: 0.6771 - val_recall: 0.4159 - val_auc: 0.8830\n",
      "\n",
      "Epoch 00007: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 8/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2605 - binary_accuracy: 0.8932 - precision: 0.6831 - recall: 0.4113 - auc: 0.8835 - val_loss: 0.2630 - val_binary_accuracy: 0.8911 - val_precision: 0.6884 - val_recall: 0.3858 - val_auc: 0.8820\n",
      "\n",
      "Epoch 00008: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 9/20\n",
      "1277/1277 [==============================] - 127s 99ms/step - loss: 0.2604 - binary_accuracy: 0.8931 - precision: 0.6820 - recall: 0.4126 - auc: 0.8839 - val_loss: 0.2624 - val_binary_accuracy: 0.8913 - val_precision: 0.6893 - val_recall: 0.3866 - val_auc: 0.8824\n",
      "\n",
      "Epoch 00009: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 10/20\n",
      "1277/1277 [==============================] - 125s 98ms/step - loss: 0.2599 - binary_accuracy: 0.8934 - precision: 0.6839 - recall: 0.4113 - auc: 0.8839 - val_loss: 0.2611 - val_binary_accuracy: 0.8915 - val_precision: 0.6745 - val_recall: 0.4135 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00010: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 11/20\n",
      "1277/1277 [==============================] - 126s 99ms/step - loss: 0.2598 - binary_accuracy: 0.8934 - precision: 0.6836 - recall: 0.4126 - auc: 0.8841 - val_loss: 0.2623 - val_binary_accuracy: 0.8917 - val_precision: 0.7014 - val_recall: 0.3754 - val_auc: 0.8827\n",
      "\n",
      "Epoch 00011: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 12/20\n",
      "1277/1277 [==============================] - 129s 101ms/step - loss: 0.2601 - binary_accuracy: 0.8932 - precision: 0.6822 - recall: 0.4129 - auc: 0.8836 - val_loss: 0.2618 - val_binary_accuracy: 0.8917 - val_precision: 0.6836 - val_recall: 0.4006 - val_auc: 0.8831\n",
      "\n",
      "Epoch 00012: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 13/20\n",
      "1277/1277 [==============================] - 127s 99ms/step - loss: 0.2596 - binary_accuracy: 0.8935 - precision: 0.6830 - recall: 0.4139 - auc: 0.8842 - val_loss: 0.2618 - val_binary_accuracy: 0.8918 - val_precision: 0.6883 - val_recall: 0.3954 - val_auc: 0.8830\n",
      "\n",
      "Epoch 00013: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 14/20\n",
      "1277/1277 [==============================] - 126s 98ms/step - loss: 0.2595 - binary_accuracy: 0.8934 - precision: 0.6839 - recall: 0.4116 - auc: 0.8841 - val_loss: 0.2607 - val_binary_accuracy: 0.8924 - val_precision: 0.6750 - val_recall: 0.4251 - val_auc: 0.8836\n",
      "\n",
      "Epoch 00014: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 15/20\n",
      "1277/1277 [==============================] - 130s 101ms/step - loss: 0.2596 - binary_accuracy: 0.8934 - precision: 0.6834 - recall: 0.4133 - auc: 0.8842 - val_loss: 0.2608 - val_binary_accuracy: 0.8923 - val_precision: 0.6770 - val_recall: 0.4199 - val_auc: 0.8838\n",
      "\n",
      "Epoch 00015: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 16/20\n",
      "1277/1277 [==============================] - 133s 104ms/step - loss: 0.2594 - binary_accuracy: 0.8937 - precision: 0.6864 - recall: 0.4117 - auc: 0.8844 - val_loss: 0.2617 - val_binary_accuracy: 0.8913 - val_precision: 0.6798 - val_recall: 0.4022 - val_auc: 0.8831\n",
      "\n",
      "Epoch 00016: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 17/20\n",
      "1277/1277 [==============================] - 130s 102ms/step - loss: 0.2591 - binary_accuracy: 0.8939 - precision: 0.6862 - recall: 0.4150 - auc: 0.8845 - val_loss: 0.2616 - val_binary_accuracy: 0.8918 - val_precision: 0.6808 - val_recall: 0.4067 - val_auc: 0.8831\n",
      "\n",
      "Epoch 00017: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1277/1277 [==============================] - 128s 100ms/step - loss: 0.2592 - binary_accuracy: 0.8936 - precision: 0.6842 - recall: 0.4142 - auc: 0.8843 - val_loss: 0.2621 - val_binary_accuracy: 0.8915 - val_precision: 0.6865 - val_recall: 0.3930 - val_auc: 0.8825\n",
      "\n",
      "Epoch 00018: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 19/20\n",
      "1277/1277 [==============================] - 131s 103ms/step - loss: 0.2592 - binary_accuracy: 0.8935 - precision: 0.6844 - recall: 0.4123 - auc: 0.8845 - val_loss: 0.2622 - val_binary_accuracy: 0.8914 - val_precision: 0.6925 - val_recall: 0.3834 - val_auc: 0.8825\n",
      "\n",
      "Epoch 00019: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n",
      "Epoch 20/20\n",
      "1277/1277 [==============================] - 145s 114ms/step - loss: 0.2595 - binary_accuracy: 0.8938 - precision: 0.6862 - recall: 0.4142 - auc: 0.8843 - val_loss: 0.2612 - val_binary_accuracy: 0.8920 - val_precision: 0.6925 - val_recall: 0.3914 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00020: saving model to /home/luke/tmp_volmodels/no_text/no_text.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f38884460>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {}\n",
    "config['model_name'] = 'no_text'\n",
    "config['build_from_scratch'] = True\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 128\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90 \n",
    "config['tokenizer'] = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "config['n_sc_id_classes'] = len(sc_id_encoder.classes_)\n",
    "config['checkpoint_path'] = DATA_VOL + \"models/\" + config['model_name'] +\"/\" + config['model_name'] +\".ckpt\"\n",
    "config['log_dir'] = DATA_VOL + \"logs/fit/\"+config['model_name']+\"_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['epochs'] = 20\n",
    "config['learning_rate'] = 1e-3\n",
    "config['model_location'] = model_location = DATA_VOL + \"models/\"+config['model_name']+\"/full_model.h5\"\n",
    "\n",
    "b = deepLegisNoText(config)\n",
    "b.load_data(df)         \n",
    "b.build()\n",
    "b.deep_legis_model.summary()\n",
    "b.train()\n",
    "#a = legislationDatasetPartisanLean(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-text, batch=4, time = 390s, or 9ms/step\n",
    "# no-text, batch=64 time = 277s, or 107ms/step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "computational-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.deep_legis_model.save(config['model_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-miniature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-biography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infectious-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.data.read_parallel import read_parallel_local\n",
    "from src.models.deeplegis import *\n",
    "from src.models.data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "successful-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 334\n",
      "Reduced number of examples:  334\n",
      "Took 0.020017449061075845 min to open 334 files with 20 processes.\n"
     ]
    }
   ],
   "source": [
    "REDUCE_BY_FACTOR = 1 # Make the dataset smaller for development purposes\n",
    "train_test_ratio = 0.91\n",
    "train_valid_ratio = 0.90\n",
    "\n",
    "if 'DATA_VOL' not in os.environ:\n",
    "    # Manually set:\n",
    "    DATA_VOL = '/home/luke/tmp_vol'\n",
    "else:\n",
    "    DATA_VOL = os.environ['DATA_VOL']\n",
    "    \n",
    "# Pre-wrangled metadata\n",
    "df = pd.read_csv(\"../references/derived/ml_data.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "df.id = df.id.astype(int)    \n",
    "print(f\"Original number of examples: {len(df)}\")\n",
    "df = df.sample(n=int(len(df)/REDUCE_BY_FACTOR)) #\n",
    "print(f\"Reduced number of examples:  {len(df)}\")\n",
    "\n",
    "tmp = read_parallel_local(df['id'], DATA_VOL + \"/clean/\")\n",
    "df['text'] = tmp\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "sc_id_encoder = LabelEncoder()\n",
    "df['sc_id_cat'] = sc_id_encoder.fit_transform(df['sc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (272, 8)\n",
      "Validation size: (31, 8)\n",
      "Test size: (31, 8)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "partisan_lean (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "version_number (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sc_id (InputLayer)              [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 18)           0           partisan_lean[0][0]              \n",
      "                                                                 version_number[0][0]             \n",
      "                                                                 sc_id[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "no_text_dense_layer (Dense)     (None, 700)          13300       tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 700)          0           no_text_dense_layer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            701         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,001\n",
      "Trainable params: 14,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 63ms/step - loss: 0.6808 - binary_accuracy: 0.6458 - precision_3: 0.5123 - recall_3: 0.1892 - auc_3: 0.5939\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 128\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90 \n",
    "config['tokenizer'] = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "config['n_sc_id_classes'] = len(sc_id_encoder.classes_)\n",
    "config['checkpoint_path'] = DATA_VOL + \"models/no_text/no_text2.ckpt\"\n",
    "config['log_dir'] = DATA_VOL + \"logs/fit/no_text2_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['epochs'] = 20\n",
    "config['learning_rate'] = 1e-3\n",
    "b = deepLegisNoText(config)\n",
    "b.load_data(df)         \n",
    "b.build()\n",
    "b.deep_legis_model.summary()\n",
    "b.train()\n",
    "#a = legislationDatasetPartisanLean(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-text, batch=4, time = 390s, or 9ms/step\n",
    "# no-text, batch=64 time = 277s, or 107ms/step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "computational-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = DATA_VOL + \"models/no_text2/full_model.h5\"\n",
    "b.deep_legis_model.save(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-miniature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-biography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

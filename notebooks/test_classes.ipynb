{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "northern-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "from src.data.read_parallel import read_parallel_local\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.deeplegis import *\n",
    "from src.models.data_loader import *\n",
    "from transformers import LongformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "driving-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of examples: 334\n",
      "Reduced number of examples:  334\n",
      "Took 0.006455898284912109 min to open 334 files with 20 processes.\n"
     ]
    }
   ],
   "source": [
    "REDUCE_BY_FACTOR = 1 # Make the dataset smaller for development purposes\n",
    "train_test_ratio = 0.91\n",
    "train_valid_ratio = 0.90\n",
    "\n",
    "if 'DATA_VOL' not in os.environ:\n",
    "    # Manually set:\n",
    "    DATA_VOL = '/datavol/'\n",
    "else:\n",
    "    DATA_VOL = os.environ['DATA_VOL']\n",
    "    \n",
    "# Pre-wrangled metadata\n",
    "df = pd.read_csv(\"../references/derived/ml_data.csv\", encoding=\"latin1\", parse_dates=True)\n",
    "df.id = df.id.astype(int)    \n",
    "print(f\"Original number of examples: {len(df)}\")\n",
    "df = df.sample(n=int(len(df)/REDUCE_BY_FACTOR)) #\n",
    "print(f\"Reduced number of examples:  {len(df)}\")\n",
    "\n",
    "tmp = read_parallel_local(df['id'], DATA_VOL + \"/clean/\")\n",
    "df['text'] = tmp\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "sc_id_encoder = LabelEncoder()\n",
    "df['sc_id_cat'] = sc_id_encoder.fit_transform(df['sc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "supposed-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['max_length'] = 128\n",
    "config['train_batch_size'] = 4\n",
    "config['testing'] = False\n",
    "config['train_test_ratio'] = 0.91\n",
    "config['train_valid_ratio'] = 0.90 \n",
    "config['tokenizer'] = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "config['n_sc_id_classes'] = len(sc_id_encoder.classes_)\n",
    "config['checkpoint_path'] = \"/data/models/no_text.ckpt\"\n",
    "config['log_dir'] = \"/data/logs/\"\n",
    "config['epochs'] = 2\n",
    "                                \n",
    "#a = legislationDatasetPartisanLean(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "animated-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = deepLegisAll(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "consolidated-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (272, 8)\n",
      "Validation size: (31, 8)\n",
      "Test size: (31, 8)\n"
     ]
    }
   ],
   "source": [
    "b.load_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "smoking-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(4, 128), dtype=int32, numpy=\n",
      "array([[    0,    11,     5,    76,     9,    84, 30722,    80,  7673,\n",
      "        40126,    41,  1760,    28,    24, 14673,    30,     5, 22437,\n",
      "            8,   790,     9,  4844,    11,   937,   461, 24228,    35,\n",
      "        35651,    35,   134, 12418, 10765,   131, 26613,     4, 19338,\n",
      "          910, 11146, 25758,    35,  2518,     7,  1166,    25,  3905,\n",
      "           35, 25758,    35,  2518, 26613,     4,    11,    42, 28764,\n",
      "           35,   939,     4,    22,  4929, 17809,   839,     5, 12418,\n",
      "        10765,   792,  2885,    11,   910, 11146, 25758,    35,  2518,\n",
      "           12,   102,     4, 42661,     4,    22, 12623, 23862, 30170,\n",
      "        23538, 17809,   839,   143,   621,  4009,    11,     5,  8809,\n",
      "            6, 21529,     6,     8,  5989,     9, 23321,  4550,  2550,\n",
      "         8462,  1728,    50,  1632,  1123,  1897, 14636,  1887,  4010,\n",
      "           13,  4860,   304,     6,  1804,     7,  4860,  5418,  3841,\n",
      "          268,     8,    49, 13228,   154,  1743,     6,  1897, 25901,\n",
      "        13657,     2],\n",
      "       [    0,    11,     5,    76,     9,    84, 30722,    80,  7673,\n",
      "        40126,    41,  1760,  1437,    28,    24, 14673,    30,     5,\n",
      "        22437,     8,   790,     9,  4844,    11,   937,   461, 24228,\n",
      "           35,  1093,  1911,   451,   131, 11150,    13,  3525,     9,\n",
      "          542, 26829,   451,   131,  3708,  1997,     4, 19338,   910,\n",
      "        11146, 35757,    35,  1244,     7,  1166,    25,  3905,    35,\n",
      "        35757,    35,  1244,  3708,  1997,     4,   358,   215, 43833,\n",
      "         5658,     6,    15,    50,   137,     5, 17008,   183,     9,\n",
      "          349,   353,     6, 11189,     8,  2870,    19,     5,  7236,\n",
      "            6,    10,   445,   223, 14270,  4631,    70,  1911,  1986,\n",
      "            8,  3749,     9,  1911,    50,   686,  2553, 24754, 17987,\n",
      "         4075,    30,  1437,     5, 43833,   223,    39,    50,    69,\n",
      "           26,  4385,   148,     5,  7127,   353,   220, 25029,     6,\n",
      "         1311,     5,   766,     9,     5,   138, 10392,   349,     9,\n",
      "           26,     2],\n",
      "       [    0,   579,   326,    10,   326,   364,  1021,   856,   295,\n",
      "          364,   885,  1423,  1021,   910,   449,  1675,  5453,   939,\n",
      "          295,   579,   364,   295,    10,   326,   364, 10408, 16705,\n",
      "          954,  2942,    30, 22583,     4, 16785,  1488,  1166,  2330,\n",
      "            8,  2740, 11118,     6,     8,    77, 11118,     7,    28,\n",
      "         2021,     7,     5,  1540,    15,  4264,    41,  1760,     7,\n",
      "        19338,     5,  1155,     8,  1703,   488,     6,    11,  9355,\n",
      "            7, 19289,    10,  1393,     7,    45,    33,    10,   865,\n",
      "           15,     5, 12216,  9562,     9,    10,  1155,   150,    10,\n",
      "         1428, 11767,   467,    16,  4009,     5,    82,     9,     5,\n",
      "          194,     9,    92,  1423,  9657,     6,  4625,    11, 22437,\n",
      "            8,  6559,     6,   109, 17890,    25,  3905,    35,  1437,\n",
      "            9,     5,  1155,     8,  1703,   488,     6,    25, 13522,\n",
      "           30,  7285,     9,     5,  2074,     9,    16, 13522,     7,\n",
      "         1166,     2],\n",
      "       [    0,    11,     5,    76,     9,    84, 30722,    80,  7673,\n",
      "        40126,    41,  1760,    28,    24, 14673,    30,     5, 22437,\n",
      "            8,   790,     9,  4844,    11,   937,   461, 24228,    35,\n",
      "        20750,    35,   134,   304,     9,  5194,    13, 18441,  6216,\n",
      "          131, 31646,  3237,     4,   910, 11146, 18461,    12,  1178,\n",
      "           35,   406,     6,  3023,    16, 29643,     8,   769,   225,\n",
      "        29179,     7,  1166,    25,  3905,    35,  3023,     4,   114,\n",
      "            5,  1494, 23483,    14,   519,   943,  3237,    13,     5,\n",
      "        22946,   154,     9, 18441,  5194,    16,  2139,     7, 17327,\n",
      "            8,  4296,   972,     5,   782,     9,  7310,  1484,     8,\n",
      "         8034, 21650,     6,     5,  1494,   189, 29080,     5,  3626,\n",
      "         1416,  5228,  1220,     7,  4303,    11, 18381,   911,   132,\n",
      "            6,     8,     7,  5242,    10,   200, 31646,  2259,   624,\n",
      "          167,   276, 18381,   911,     4,    10,   200, 31646,  2259,\n",
      "         5658,     2]], dtype=int32)>, 'partisan_lean': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6082628, 0.6082628, 0.7381234, 0.6082628], dtype=float32)>, 'version_number': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 2., 1.], dtype=float32)>, 'sc_id': <tf.Tensor: shape=(4, 16), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "      dtype=float32)>}, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 0, 0, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for elem in b.train_batches.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "resistant-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFLongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "b.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "thick-feeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "longformer (TFLongformerMainLay TFLongformerBaseMode 148068864   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 768)          0           longformer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_308 (Dropout)           (None, 768)          0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "partisan_lean (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "version_number (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sc_id (InputLayer)              [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (None, 786)          0           dropout_308[0][0]                \n",
      "                                                                 partisan_lean[0][0]              \n",
      "                                                                 version_number[0][0]             \n",
      "                                                                 sc_id[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 700)          550900      tf.concat_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_309 (Dropout)           (None, 700)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            701         dropout_309[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 148,620,465\n",
      "Trainable params: 148,620,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "b.deep_legis_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "sound-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 0.6891 - binary_accuracy: 0.5661 - precision_6: 0.4065 - recall_6: 0.7303 - auc_6: 0.6635 - val_loss: 0.6839 - val_binary_accuracy: 0.7143 - val_precision_6: 0.5333 - val_recall_6: 0.8889 - val_auc_6: 0.7632\n",
      "\n",
      "Epoch 00001: saving model to /data/models/no_text.ckpt\n",
      "Epoch 2/2\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.6807 - binary_accuracy: 0.6552 - precision_6: 0.5272 - recall_6: 0.7811 - auc_6: 0.7444 - val_loss: 0.6777 - val_binary_accuracy: 0.7143 - val_precision_6: 0.5333 - val_recall_6: 0.8889 - val_auc_6: 0.7924\n",
      "\n",
      "Epoch 00002: saving model to /data/models/no_text.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f170af0d2b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-technology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-missouri",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
